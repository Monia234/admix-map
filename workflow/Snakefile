# Load modules
import glob
import os
import math
import pdb
import shutil
import pandas as pd
import scipy.stats
import yaml
import random
import copy

# Get the date
from datetime import datetime
i = datetime.now()
TIME = i.strftime('%Y-%m-%d')

# Specify config file
configfile: "workflow/config.yml"

# Parse config.yml file
QUERY = config['query']
RFMIX = config['admixMapping']['rfmix']

# Make subdirectories
dirs = [f"{os.getcwd()}/{x}" for x in ["input", "accessory", "plink", "plink/DS", "BLINK", "OandE", "data", "sHWE", "scripts", "figures", "figures/chrom_plots"]]
for directory in dirs:
    if not os.path.exists(directory): os.mkdir(directory)

if config['singularity']['use_singularity'] == 'true' and config['singularity']['image'] != "none":
    bind_paths = ",".join(set([os.path.dirname(x) for x in [QUERY, config['samples'], config['annotation']['rsIDs'], config['annotation']['typed_key']]] + dirs + [RFMIX]))
    CMD_PREFIX = f"set +u; {config['singularity']['module']}; singularity exec --bind {bind_paths} {config['singularity']['image']}"
    CODE = config['singularity']['code']
else:
    CMD_PREFIX = config['cmd_prefix']
    CODE = config['dir']['code']

BASE = config['outname']  # Base prefix used for naming files is set as basename of
INPUT = f"input/{BASE}"

samps = [] # Create list containing all samples in original input fam file
with open (f"{QUERY}.fam") as fam_file:
    for line in fam_file:
        line = line.strip().split()
        samps.append(line[1].replace("#", ""))

#Retrieve control individuals; Determine number of controls from .fam file
assert config['samples'] == 'all' or os.path.exists(config['samples']), print("'samples' must be set to 'all' or a valid path to PLINK-format (FID IID) text file in config file")
if config['samples'] == 'all': ind_num = len(samps)
elif os.path.exists(config['samples']):
    ind_num = 0
    with open(config['samples'], 'r') as samp_file:
        for ind in samp_file:
            if ind.strip().split()[1] in samps: ind_num += 1

# Determine number of pairwise comparisons of individuals necessary for IBD/IBS calculation in PLINK and convert this to the number of necessary jobs
comparisons = ind_num * (ind_num - 1) / 2
comparisons_per_job = int(config['IBD']['cpj'])
num_jobs = math.ceil(comparisons / comparisons_per_job)
if num_jobs <= 1: # Attempt to catch an error that arises in instances where there are not that many jobs to run
    comparisons_per_job = comparisons_per_job / 100
    num_jobs = math.ceil(comparisons / comparisons_per_job)

# Determine jobs to run locally vs on cluster.  Also coordinate resource management for PLINK.
plink_run_specs = {'__default__': ""} # Set default to empty string in case of local run.  i.e. default to plink's auto-detection of resources
if config['run_settings']['local_run'] == 'true':
    localrules: all, calcFreq, calcIBS, catIBS, calcPCA, controlMatch, admixMap, blink_GWAS, extract_optimum_popnum, cat_admixMap
else:
    localrules: all, extract_optimum_popnum, cat_admixMap
    assert config['run_settings']['scheduler'] in ['pbs', 'slurm'], print(f"\nThe scheduler specified at run_settings -> scheduler: \'{config['run_settings']['scheduler']}\' is invalid.\n")
    assert os.path.exists(config['run_settings']['cluster_config']), print(f"\nMust provide a cluster configuration file under run_settings -> cluster_config in the config.yml file\nFile \'{config['run_settings']['cluster_config']}\' does not exist\n")
    clusterfile = yaml.load(open(config['run_settings']['cluster_config']), Loader=yaml.FullLoader)
    for rule in clusterfile.keys(): # Purpose of this code is to make sure plink requests same amount of memory/threads as specified in cluster.yaml file
        if config['run_settings']['scheduler'] == 'slurm': plink_run_specs[rule] = f"--memory {int(clusterfile[rule]['mem-per-cpu'].replace('G','000')) * int(clusterfile[rule]['ntasks'])} --threads {clusterfile[rule]['ntasks']}"
        elif config['run_settings']['scheduler'] == 'pbs':  plink_run_specs[rule] = f"--memory {clusterfile[rule]['mem'].replace('b','').replace('m','').replace('g','000')} --threads 1"


#### DEFINE FUNCTIONS #####
def get_all_inputs(wildcards):
    input_list = ["accessory/.sHWE_pass.txt", f"sHWE/.optimum_popnum.txt", f"{BASE}-rulegraph.png",
                  f"plink/{BASE}_LDp_sHWE.bed", f"{BASE}.admixmap.txt", f"{QUERY}.bed", f"plink/{BASE}.eigenvec",
                  f"accessory/samples.txt", f"input/{BASE}_CtlMat.bed", f"plink/{BASE}.genome.gz",
                  f"{BASE}.blink.txt", f"{BASE}.genesis.txt", f"{BASE}-Mapping-report.pdf", f"{BASE}.genesis.sig.annt.txt", f"{BASE}.blink.sig.annt.txt", f"{BASE}.admixmap.annt.txt"]
    if config['admixMapping']['skip'] != 'true': input_list.append(f"{BASE}.admixmap.txt")
    return(input_list)

def get_cM_inputs(wildcards):
    input_list = [f"plink/{BASE}_LDp_sHWE_IBDflt.bed"]
    if config['match_controls'] == 'true':
        input_list.append(f"plink/{BASE}.genome.gz")
    return(input_list)

def get_dataprep_input(wildcards):
    input_list = ["accessory/samples.txt", f"{BASE}.globalancestry.txt"]
    inFile = [f"{RFMIX.rstrip('/')}/{x}" for x in os.listdir(RFMIX) if x.endswith(f"chr{wildcards.CHROM}.msp.tsv")]
    assert len(inFile) == 1
    return(input_list + inFile + ["accessory/excluded_related_samples.txt"])

def get_report_input(wildcards):
    input_list = [f"{BASE}.blink.txt", f"{BASE}-rulegraph.png", f"{BASE}.genesis.txt"]
    if config['admixMapping']['skip'] != 'true': input_list += [f"{BASE}.admixmap.txt", f"{BASE}.globalancestry.txt"]
    return(input_list)

def get_conditional_analysis_input(wildcards):
    inputList = []
    with open(config['conditional_analysis']['snp_list'],'r') as snp_list: # One column with snpIDs
        for line in snp_list:
            marker = line.strip().replace(":", "-")
            inputList.append(f"conditional-analysis/{BASE}-{marker}.genesis.txt")
    return(inputList)

def plnk_rsrc(rule_name, plink_specs):
    try: resources = plink_specs[rule_name]
    except KeyError: resources = plink_specs['__default__']
    return(resources)

#### DEFINE RULES FOR PIPELINE EXECUTION #####
rule all:
    input: get_all_inputs

rule clean:
    shell:
        "rm -r input; rm -r plink/*; rm -r data; rm *txt; rm accessory/*"

rule make_rulegraph:
    output: f"{BASE}-rulegraph.png"
    shell: f"snakemake --rulegraph --configfile workflow/config.yml > accessory/Pipeline_DAG.dot; {CMD_PREFIX} dot -Tpng accessory/Pipeline_DAG.dot > {{output}}"

rule subset_individuals:
    input: f"{QUERY}.bed"
    output: f"plink/{BASE}_sub.bed", f"plink/{BASE}_sub_ctrls.bed"
    params: awk_string = "\'{if($6==1) print $1,$2}' " + f"plink/{BASE}_sub.fam > accessory/control_samples.txt"
    run:
        if config['samples'] == 'all':
            shell(f"{CMD_PREFIX} plink --bfile {QUERY} --keep-allele-order --make-bed --maf {config['gwas']['maf']} --out plink/{BASE}_sub {plnk_rsrc(rule, plink_run_specs)}; "
                  f"sed -i 's/#//g' plink/{BASE}_sub.fam")  #Pound sign causes issues with R in subsequent steps
        elif os.path.exists(config['samples']):
            shell(f"{CMD_PREFIX} plink --bfile {QUERY} --keep {config['samples']} --keep-allele-order --maf {config['gwas']['maf']} --allow-no-sex --make-bed --out plink/{BASE}_sub {plnk_rsrc(rule, plink_run_specs)};"
                  f"sed -i 's/#//g' plink/{BASE}_sub.fam")
        shell(f"{CMD_PREFIX} awk {{params.awk_string}}; {CMD_PREFIX} plink --bfile plink/{BASE}_sub --keep accessory/control_samples.txt --make-bed --out plink/{BASE}_sub_ctrls {plnk_rsrc(rule, plink_run_specs)}")

rule filter_missingness_by_case:
    input: f"plink/{BASE}_sub.bed", f"plink/{BASE}_sub_ctrls.bed"
    output: f"plink/{BASE}_sub_mflt.bed", f"plink/{BASE}_sub_ctrls_mflt.bed"
    run:
        import pandas as pd
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub --test-missing --allow-no-sex --out plink/{BASE}_sub")
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub --missing --allow-no-sex --out plink/{BASE}_sub")
        mbc = pd.read_table(f"plink/{BASE}_sub.missing", sep = r"\s+")
        mis = pd.read_table(f"plink/{BASE}_sub.lmiss", sep = r"\s+")
        dat = pd.concat([mbc[mbc['P'] < float(config['gwas']['mbc_pval'])]['SNP'], mis[mis['F_MISS'] > float(config['gwas']['missingness'])]['SNP']]).drop_duplicates()
        dat.to_csv('accessory/missing_filter.txt', header=False,index=False)
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub --exclude accessory/missing_filter.txt --keep-allele-order --make-bed --out plink/{BASE}_sub_mflt")
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_ctrls --exclude accessory/missing_filter.txt --keep-allele-order --make-bed --out plink/{BASE}_sub_ctrls_mflt")

rule LD_prune:
    input: f"plink/{BASE}_sub_ctrls_mflt.bed"
    output: f"plink/{BASE}_LDprune_ctrls.bed", f"plink/{BASE}.LDkeep.prune.in", f"plink/{BASE}_LDprune.bed"
    params:
        WS = config['LD_pruning']['window_size'],
        SS = config['LD_pruning']['step_size'],
        RT = config['LD_pruning']['r2_threshold']
    shell:
        f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_ctrls_mflt --indep-pairwise {{params.WS}} {{params.SS}} {{params.RT}} --out plink/{BASE}.LDkeep {plnk_rsrc(rule, plink_run_specs)}; "
        f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_ctrls_mflt --extract plink/{BASE}.LDkeep.prune.in --make-bed --out plink/{BASE}_LDprune_ctrls {plnk_rsrc(rule, plink_run_specs)};"
        f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --extract plink/{BASE}.LDkeep.prune.in --make-bed --out plink/{BASE}_LDprune {plnk_rsrc(rule, plink_run_specs)}"

rule calcFreq:
    input: f"plink/{BASE}_LDprune.bed"
    output: f"plink/{BASE}_LDprune.frq"
    shell:
        f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDprune --freq --out plink/{BASE}_LDprune {plnk_rsrc(rule, plink_run_specs)}"

rule calcIBS:
    input: f"plink/{BASE}_LDprune.bed", f"plink/{BASE}_LDprune.frq"
    output: f"plink/{BASE}.genome.{{job}}"
    shell:
        f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDprune --maf {config['IBD']['maf']} --read-freq plink/{BASE}_LDprune.frq --genome --parallel {{wildcards.job}} {num_jobs} --out plink/{BASE} {plnk_rsrc(rule, plink_run_specs)}"

rule catIBS:
    input: expand(f"plink/{BASE}.genome.{{job}}", job=range(1, num_jobs +1))
    output: f"plink/{BASE}.genome.gz"
    run:
        shell(f"{CMD_PREFIX} cat plink/{BASE}.genome.* | gzip > {BASE}.genome.gz; mv {BASE}.genome.gz plink")

rule IBD_filter_ctrls:
    input: f"plink/{BASE}_LDprune_ctrls.bed", f"plink/{BASE}.genome.gz"
    output: f"plink/{BASE}_LDp_ctrls_IBDflt.bed"
    params:
        awk_string = "\'{if($10>" + config['IBD']['pi_hat'] + ") print $0}\' > accessory/related_IBS_ctrls.txt"
    run:
        shell(f"zcat {{input[1]}} | awk {{params.awk_string}}; "
              f"{CMD_PREFIX} Rscript scripts/filter_relateds.R -r accessory/related_IBS_ctrls.txt -o accessory/excluded_related_ctrls.txt; "
              f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDprune_ctrls --remove accessory/excluded_related_ctrls.txt --keep-allele-order --make-bed --out plink/{BASE}_LDp_ctrls_IBDflt {plnk_rsrc(rule, plink_run_specs)}")

# Downsample controls.  The implementation of sHWE currently does not allow ANY missing data.
# For large control datasets, this requirement will remove many many sites, especially if using imputed data.
# Tough thing is...will need to create many different random(or fixed?) subsets of individuals in order to minimize stochastic loss of snp data.
# 1 - Pr[x=0]
# Pr[notMissing] <= 1 - Pr[missing] = 1 - 0.05 = 0.95
# Pr[numMiss=0 out of N individuals] = Pr[notMissing]^N
# If N=50, this equals 0.0769
# So for random sample of 50 individuals, and 2Million markers, we'd expect ~150k would be testable (i.e. complete genotype data)
# With 100 individuals, you'd only get ~12k markers per downsample.  If no overlap in markers tested per downsample (best-case scenario), ~167 jobs would be required to test all 2Million SNPs
# With 50, you'd need 13 jobs.
rule generate_downsample_controls:
    input: f"plink/{BASE}_LDp_ctrls_IBDflt.bed"
    output: f"plink/DS/{BASE}_LDprune_ctrls_DS{{round}}.txt"
    shell: f"{CMD_PREFIX} shuf -n {config['sHWE']['downsample_number']} plink/{BASE}_LDp_ctrls_IBDflt.fam > plink/DS/{BASE}_LDprune_ctrls_DS{{wildcards.round}}.txt"

rule downsample_controls:
    input: f"plink/DS/{BASE}_LDprune_ctrls_DS{{round}}.txt"
    output: f"plink/DS/{BASE}_LDprune_ctrls_DS{{round}}.bed"
    run:
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDp_ctrls_IBDflt --keep plink/DS/{BASE}_LDprune_ctrls_DS{{wildcards.round}}.txt --maf {config['sHWE']['maf']} "
              f"--geno 0.0 --keep-allele-order --make-bed --out plink/DS/{BASE}_LDprune_ctrls_DS{{wildcards.round}} {plnk_rsrc(rule, plink_run_specs)}")

rule calc_downsampled_coverage:
    input: expand(f"plink/DS/{BASE}_LDprune_ctrls_DS{{round}}.bed", round = range(0, int(config['sHWE']['downsample_rounds'])))
    output: "accessory/sHWE_downsampled_snps.txt"
    shell: f"cat plink/DS/{BASE}_LDprune_ctrls_DS*.bim | sort | uniq > accessory/sHWE_downsampled_snps.txt"

rule downsample_checkpoint:
    input: "accessory/sHWE_downsampled_snps.txt"
    output: "accessory/.sHWE_downsample_pass.txt"
    run:
        with open('accessory/sHWE_downsampled_snps.txt', 'r') as tested:
            for num_tested, line in enumerate(tested): pass
        if num_tested < int(config['sHWE']['test_threshold']):
            print(f"Failed Checkpoint\nReason: Fewer than {config['sHWE']['test_threshold']} unique SNPs downsampled for sHWE\n"
                  f"Increase the value set for \'downsample_rounds\' entry in the \'sHWE\' section of the config file")
            shell("cp accessory/sHWE_downsampled_snps.txt accessory/.sHWE_downsampled_snps.txt; rm accessory/sHWE_downsampled_snps.txt")
        else:
            shell('touch accessory/.sHWE_downsample_pass.txt')

rule optimize_sHWE:
    input: expand(f"plink/DS/{BASE}_LDprune_ctrls_DS{{round}}.bed", round=[x for x in range(0,int(config['sHWE']['downsample_rounds']))]), "accessory/.sHWE_downsample_pass.txt"
    output: f"sHWE/{BASE}_sHWE_{{d}}"
    shell:
        f"{CMD_PREFIX} Rscript {CODE}/run_sHWE.R -p plink/DS/{BASE}_LDprune_ctrls_DS0 -d {{wildcards.d}} -o sHWE/{BASE}_sHWE_{{wildcards.d}}"

#TODO Add checks to only open files that are not 0 bytes.  For whatever reason, the sHWE is failing for some population numbers.
rule extract_optimum_popnum:
    input: expand(f"sHWE/{BASE}_sHWE_{{d}}", d=config['sHWE']['pop_nums'].split(","))
    output: f"sHWE/.optimum_popnum.txt", "sHWE/entropy.txt"
    params:
        bins = int(config['sHWE']['bins'])
    run:
        max_entropy = -9
        best_popnum = -9
        with open("sHWE/entropy.txt", 'w') as ent_file:
            for file in input:
                if not os.stat(file).st_size == 0:
                    popnum = file.split("_")[-1]
                    dat = pd.read_table(file, header=None) # read in vector of p-values from sHWE
                    binned = pd.cut(dat.iloc[:,0], params.bins).value_counts(sort=False) # bin and count vector values
                    entropy = scipy.stats.entropy(binned.iloc[1:,]) # Calculate entropy of bin counts, excluding first bin that corrresponds to bin containing true positives (i.e. sites truly out of HWE)
                    ent_file.write(f"{popnum}\t{entropy}\n")
                    if entropy > max_entropy:
                        best_popnum = popnum
                        max_entropy = entropy
                else:
                    print(f"sHWE calculation failed for {popnum}; debug or remove this value from sHWE -> pop_nums in the config.yml file")
        assert(max_entropy != -9 and best_popnum != -9)
        with open("sHWE/.optimum_popnum.txt", 'w') as outfile: outfile.write(str(best_popnum))

rule structHWE:
    input: f"plink/DS/{BASE}_LDprune_ctrls_DS{{f}}.bed", f"sHWE/.optimum_popnum.txt", "sHWE/entropy.txt"
    output: f"sHWE/{BASE}_sHWE-DS{{f}}"
    params: threshold = config['sHWE']['threshold']
    run:
        popfile = open(f"sHWE/.optimum_popnum.txt", 'r')
        popnum = popfile.readline()
        popfile.close()
        shell(f"{CMD_PREFIX} Rscript {CODE}/run_sHWE.R -p plink/DS/{BASE}_LDprune_ctrls_DS{{wildcards.f}} -d {popnum} -t {{params.threshold}} -o sHWE/{BASE}_sHWE-DS{{wildcards.f}} || touch sHWE/{BASE}_sHWE-DS{{wildcards.f}}")

rule calc_test_coverage:
    input: expand(f"sHWE/{BASE}_sHWE-DS{{round}}", round = range(0, int(config['sHWE']['downsample_rounds'])))
    output: 'accessory/sHWE_tested_snps.txt'
    run:
        file_list = [x for x in glob.glob(f"plink/DS/{BASE}_LDprune_ctrls_DS*.bim")
                     if os.path.exists(f"sHWE/{BASE}_sHWE-DS{int(x.strip('.bim').replace('DS', '').split('_')[-1])}.rmv.bim")]
        with open('accessory/.tested_file_list.txt', 'w') as tested:
            for file in file_list: tested.write(f"{file}\n")
        if file_list: shell(f"find plink/DS/ -name \'{BASE}_LDprune_ctrls_DS*.bim\' | grep -v -w accessory/.tested_file_list.txt | xargs cat | cut -d \" \" -f 2 | sort | uniq > accessory/sHWE_tested_snps.txt")

rule check_markers_tested:
    input: 'accessory/sHWE_tested_snps.txt'
    output: "accessory/.sHWE_pass.txt"
    run:
        with open('accessory/sHWE_tested_snps.txt', 'r') as tested:
            for num_tested, line in enumerate(tested): pass
        if num_tested < int(config['sHWE']['test_threshold']):
            print(f"Failed Checkpoint\nReason: Only {num_tested} markers were tested for sHWE, which is fewer than requested threshold ({config['sHWE']['test_threshold']})\n"
                  f"Increase the value set for \'downsample_rounds\' entry in the \'sHWE\' section of the config file")
            shell("cp accessory/sHWE_tested_snps.txt accessory/.sHWE_tested_snps.txt; rm accessory/sHWE_tested_snps.txt; rm accessory/sHWE_downsampled_snps.txt")
        else:
            shell('touch accessory/.sHWE_pass.txt')

rule filter_sHWE_SNPs:
    input: "accessory/.sHWE_pass.txt"
    output: f"plink/{BASE}_LDp_sHWE.bed", f"plink/{BASE}_LDp_sHWE.bim"
    params: maf = config['sHWE']['maf']
    shell:
            f"cat sHWE/{BASE}_sHWE-DS*.rmv.bim | sort | uniq > sHWE/sHWE.rmvd.snps.bim; "
            f"cut -f 2 -d \" \" sHWE/sHWE.rmvd.snps.bim | grep -v -f - accessory/sHWE_tested_snps.txt > accessory/sHWE_kept_snps.bim; "
            f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDprune --extract accessory/sHWE_kept_snps.bim --keep-allele-order "
            f"--make-bed --maf {{params.maf}} --out plink/{BASE}_LDp_sHWE {plnk_rsrc(rule, plink_run_specs)}"

rule IBD_filter:
    input: f"plink/{BASE}_LDp_sHWE.bed", f"plink/{BASE}.genome.gz"
    output: f"plink/{BASE}_LDp_sHWE_IBDflt.bed", "accessory/excluded_related_samples.txt"
    params:
        awk_string = "\'{if($10>" + config['IBD']['pi_hat'] + ") print $0}\' > accessory/related_IBS_results.txt",
    run:
        if config['IBD']['filter_relateds'] == 'true':
            shell(f"zcat {{input[1]}} | awk {{params.awk_string}}; {CMD_PREFIX} Rscript {CODE}/filter_relateds.R -r accessory/related_IBS_results.txt -o accessory/excluded_related_samples.txt; "
                  f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDp_sHWE --remove accessory/excluded_related_samples.txt --keep-allele-order --make-bed --out plink/{BASE}_LDp_sHWE_IBDflt {plnk_rsrc(rule, plink_run_specs)}")
        else:
            shell(f"zcat {{input[1]}} | awk {{params.awk_string}}; {CMD_PREFIX} Rscript {CODE}/filter_relateds.R -r accessory/related_IBS_results.txt -o accessory/excluded_related_samples.txt; "
                  f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDp_sHWE --keep-allele-order --make-bed --out plink/{BASE}_LDp_sHWE_IBDflt {plnk_rsrc(rule, plink_run_specs)}")

rule controlMatch:
    # TODO: add option for user to provide samples file
    input: get_cM_inputs
    output: f"accessory/samples.txt", f"input/{BASE}_CtlMat.bed", f"input/{BASE}_PCA.bed"
    run:
        if config['match_controls'] == 'true':
            shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDp_sHWE_IBDflt --allow-no-sex --read-genome {{input[1]}} --cluster cc --mcc 1 {config['control_number']} --out plink/{BASE} {plnk_rsrc(rule, plink_run_specs)}; "
                  f"{CMD_PREFIX} " + "awk '{{if(NF!=2) for (i = 2; i <= NF; i++) print $i}}'" + f" plink/{BASE}.cluster1 " + f"| cut -d \"(\" -f 1 | sed 's/_/\\t/' > accessory/samples2.txt; "
                  "awk '{{split($2,a,\"_\"); printf(\"%s\\n%s\\n\",$2,a[1])}}' accessory/samples2.txt | sed 's/#//g' > accessory/samples.txt")
            shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --keep accessory/samples2.txt --make-bed --out input/{BASE}_CtlMat {plnk_rsrc(rule, plink_run_specs)}; "
                  f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDp_sHWE_IBDflt --keep accessory/samples2.txt --make-bed --out input/{BASE}_PCA {plnk_rsrc(rule, plink_run_specs)}")
        else:
            shell("{CMD_PREFIX} awk '{{split($2,a,\"_\"); printf(\"%s\\n%s\\n\",$2,a[1])}}' plink/" + BASE + "_LDp_sHWE_IBDflt.fam | sed 's/#//g' > accessory/samples.txt")
            shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --make-bed --out input/{BASE}_CtlMat {plnk_rsrc(rule, plink_run_specs)}; "
                  f"{CMD_PREFIX} plink --bfile plink/{BASE}_LDp_sHWE_IBDflt --make-bed --out input/{BASE}_PCA {plnk_rsrc(rule, plink_run_specs)}")

rule calcPCA:
    input: f"input/{BASE}_PCA.bed"
    output: f"plink/{BASE}.eigenvec"
    shell:
        f"{CMD_PREFIX} plink --bfile input/{BASE}_PCA --pca --out plink/{BASE} {plnk_rsrc(rule, plink_run_specs)}"

rule get_globalAncestry:
    input: "accessory/samples.txt"
    output: "{BASE}.globalancestry.txt"
    shell:
        f"{CMD_PREFIX} Rscript {CODE}/getGlobalAnc.R -d {RFMIX} -s accessory/samples.txt -o {{output}}"

rule admixMap_dataPrep:
    input: get_dataprep_input
    output: f"input/{BASE}_chr{{CHROM}}.admixMap.dat"
    shell: f"grep -v -f accessory/excluded_related_samples.txt accessory/samples.txt > accessory/samples_admixMap.txt; {CMD_PREFIX} Rscript {CODE}/admixMunge.R -d {{input[2]}} -g {{input[1]}} -s accessory/samples_admixMap.txt -f input/{BASE}_CtlMat.fam -o {{output}}"

rule admixMap:
    input: f"input/{BASE}_chr{{CHROM}}.admixMap.dat"
    output: f"{BASE}_chr{{CHROM}}.admixmap.txt"
    threads: 4
    shell: f"{CMD_PREFIX} Rscript {CODE}/admixMap2.R -f {{input}} -o {BASE}_chr{{wildcards.CHROM}} -P {config['admixMapping']['ancestry_predictors']} -p {config['admixMapping']['other_predictors']} -c {{threads}}"

rule cat_admixMap:
    input: expand(f"{BASE}_chr{{CHROM}}.admixmap.txt", CHROM = range(1,23))
    output: f"{BASE}.admixmap.txt"
    run:
        shell(f"head -n 1 {BASE}_chr1.admixmap.txt > header.txt; tail -q -n +2  {BASE}_chr*.admixmap.txt > body.txt; cat header.txt body.txt > {BASE}.admixmap.txt; rm header.txt; rm body.txt")

rule genesis_prep:
    input: f"plink/{BASE}_sub_mflt.bed", f"plink/{BASE}_LDp_sHWE.bim"
    output: f"{BASE}.genesis.pdat", f"{BASE}.genesis.grm.gds", f"{BASE}.genesis.gds"
    run:
        cmd = f"{CMD_PREFIX} Rscript {CODE}/genesis_prep.R -p plink/{BASE}_sub_mflt -k {{input[1]}} -n {config['gwas']['pc_num']} -o {BASE} -l {config['LD_pruning']['r2_threshold']} -t {config['kinship_threshold']}"
        if os.path.exists(config['covariate_file']): #Not tested
                cmd += f" -C {config['covariate_file']}"
        shell(cmd)

rule genesis_GWAS:
    input: f"{BASE}.genesis.gds", f"{BASE}.genesis.pdat", f"{BASE}.genesis.grm.gds"  # No control matching is done because SPA method accommodates imbalanced case/control ratios
    output: f"{BASE}.genesis.txt"
    threads: int(config['gwas']['cores'])
    run:
        cmd = f"{CMD_PREFIX} Rscript {CODE}/genesis_gwas.R -g {{input[0]}} -p {{input[1]}} -k {{input[2]}} -n {config['gwas']['pc_num']} -C {config['gwas']['other_predictors']} -o {BASE}.genesis.txt -c {{threads}}"
        shell(cmd)

rule blink_convert:
    input: f"input/{BASE}_CtlMat.bed", f"plink/{BASE}.eigenvec", f"{BASE}.genesis.pdat"
    output: f"BLINK/{BASE}_CtlMat.pos"
    run:
        with open('scripts/blink_convert.sh', 'w') as temp_sh:
            cmd = f"rm -r -f BLINK/*; chmod -R 775 BLINK/; cp -r {config['gwas']['blink_dir']}/* BLINK; " \
                  f"cp input/{BASE}* BLINK; cd BLINK; chmod 770 *; sed 's/#//g' -i {BASE}_CtlMat.fam; " \
                  f"./blink_linux --file {BASE}_CtlMat --compress --plink; cd .. ; " \
                  f"Rscript {CODE}/blink_prep.R -f BLINK/{BASE}_CtlMat.fam -d {BASE}.genesis.pdat -n {config['gwas']['pc_num']} -o BLINK/{BASE}_CtlMat "
            if os.path.exists(config['covariate_file']): #Not tested
                cmd += f"-c {config['covariate_file']}"
            temp_sh.write(cmd)
        shell(f"{CMD_PREFIX} sh scripts/blink_convert.sh")

rule blink_GWAS:
    input: f"BLINK/{BASE}_CtlMat.pos"
    output: f"{BASE}.blink.txt"
    threads: int(config['gwas']['cores'])
    run:
        with open('scripts/blink_gwas.sh', 'w') as temp_sh:
            temp_sh.write(f"cd BLINK; ./blink_linux --file {BASE}_CtlMat --binary --gwas --parallel 1 --cycle-size {threads}; cp phenotype_GWAS_result.txt ../{BASE}.blink.txt")
        shell(f"{CMD_PREFIX} sh scripts/blink_gwas.sh")

#TODO: Finish make_report for admixMap
rule make_report:
    input: get_report_input
    output: f"{BASE}-Mapping-report.pdf", f"{BASE}.admixmap.sig.txt", f"{BASE}.genesis.sig.txt", f"{BASE}.blink.sig.txt"
    run:
        with open("scripts/gather_report_data.sh", 'w') as report_cmds:
            report_line = f"echo \'rmarkdown::render(\"scripts/admixMap-report.Rmd\", output_file=\"{BASE}-Mapping-report.pdf\", " \
                          f"params=list(genesis_rslt=\"{BASE}.genesis.txt\", " \
                          f"blink_rslt=\"{BASE}.blink.txt\", " \
                          f"fam_file=\"plink/{BASE}_sub_mflt.fam\", " \
                          f"input_directory=\"input/\", " \
                          f"gen_since_admix=\"{config['admixMapping']['gen_since_admixture']}\", " \
                          f"gwas_threshold=\"{config['gwas']['sig_threshold']}\", " \
                          f"ancestry_comps=\"{config['admixMapping']['ancestry_predictors']}\", " \ 
                          f"pruned_bim=\"plink/{BASE}_LDp_sHWE.bim\", " \
                          f"sHWE_entropy=\"sHWE/entropy.txt\", " \
                          f"sHWE_markers=\"accessory/sHWE_tested_snps.txt\", " \
                          f"ibd_ctrls=\"plink/{BASE}_LDp_ctrls_IBDflt.fam\", " \
                          f"eigenval=\"{BASE}.pcair.varprop\", " \
                          f"phenodat=\"{BASE}.genesis.pdat\", " \
                          f"kinplot=\"{BASE}.kinplot.png\", " \
                          f"mflt=\"accessory/missing_filter.txt\", " \
                          f"rulegraph_file=\"{BASE}-rulegraph.png\", "
            if config['admixMapping']['skip'] != 'true':
                report_line += f"admixMap_rslt=\"{BASE}.admixmap.txt\", global_ancestry=\"{BASE}.globalancestry.txt\","
            else:
                report_line += f"admixMap_rslt=\"-9\", global_ancestry=\"-9\","
                shell(f"touch {BASE}.admixmap.sig.txt")
            report_line += f"config_file=\"workflow/config.yml\"))\' | R --vanilla"
            report_cmds.write(report_line)
        shell(f"{CMD_PREFIX} sh scripts/gather_report_data.sh; mv scripts/{BASE}-Mapping-report.pdf {BASE}-Mapping-report.pdf; mv *kinplot.png figures")

rule annotate_snps: # get genotype frequencies from VCF
    input: f"{BASE}.genesis.sig.txt", f"{BASE}.blink.sig.txt"
    output: f"{BASE}.genesis.sig.annt.txt", f"{BASE}.blink.sig.annt.txt"
    run:
        shell(f"cut -f 1 {BASE}.genesis.sig.txt > {BASE}.genesis.sigID.txt; cut -f 1 {BASE}.blink.sig.txt > {BASE}.blink.sigID.txt")
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --extract {BASE}.genesis.sigID.txt --keep-allele-order --freq case-control --allow-no-sex --recode vcf --out {BASE}.genesis.sig {plnk_rsrc(rule, plink_run_specs)}")
        shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --extract {BASE}.blink.sigID.txt --keep-allele-order --freq case-control --allow-no-sex --recode vcf --out {BASE}.blink.sig {plnk_rsrc(rule, plink_run_specs)}")
        cmd = f"{CMD_PREFIX} /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Xmx8G -jar /snpEff/snpEff.jar ann -t GRCh37.75 {BASE}.genesis.sig.vcf | " \
              "awk '{{split($8,a,\"|\"); split(a[1],b,\"=\"); print $1,$2,$4,$5,a[4],a[3],a[2],b[2]}}' | grep -v \"#\" > {BASE}.genesis.sig.preannt.txt"
        shell(cmd)
        cmd = f"{CMD_PREFIX} /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Xmx8G -jar /snpEff/snpEff.jar ann -t GRCh37.75 {BASE}.blink.sig.vcf | " \
              "awk '{{split($8,a,\"|\"); split(a[1],b,\"=\"); print $1,$2,$4,$5,a[4],a[3],a[2],b[2]}}' | grep -v \"#\" > {BASE}.blink.sig.preannt.txt"
        shell(cmd)
        for soft in ['blink','genesis']:
            cmd = f"{CMD_PREFIX} Rscript {CODE}/merge_annt.R -i {BASE}.{soft}.txt -s {BASE}.{soft}.sig.preannt.txt -r {config['annotation']['rsIDs']} -f {BASE}.{soft}.sig.frq.cc -o {BASE}.{soft}.sig.annt.txt"
            if os.path.exists(config['annotation']['typed_key']): cmd += f" -t {config['annotation']['typed_key']}"
            shell(cmd)

rule annotate_regions: # get genotype frequencies from VCF
    input: f"{BASE}.admixmap.txt", f"{BASE}.blink.sig.txt"
    output: f"{BASE}.admixmap.annt.txt"
    run:
        dat = pd.read_table(input[0], sep = r"\s+")
        dat = dat[dat['ANC.p.value'] < float(config['admixMapping']['sig_threshold'])]
        dat[['chm', 'spos', 'epos', 'ANC.estimate', 'ANC.std.error', 'ANC.statistic', 'ANC.p.value', 'anc']].to_csv(f"{BASE}.admixmap.tmp.bed", header=False, sep = "\t", index=False)
        gff = f"{os.getcwd()}/accessory/{os.path.basename(config['annotation']['gff'])}"
        if config['annotation']['download_gff'] == 'true': shell(f" wget {config['annotation']['gff']} -O {gff}")
        else: shell(f"cp {config['annotation']['gff']} {gff}")
        shell(f"{CMD_PREFIX} bedtools slop -i {BASE}.admixmap.tmp.bed -g {os.getcwd()}/accessory/hg19.genome -b {config['admixMapping']['annotation_buffer']} > {BASE}.admixmap.bed")
        cmd = f"{CMD_PREFIX} bedtools intersect -a {BASE}.admixmap.bed -b {gff} -loj | "  \
        "awk '{{if($11==\"gene\") print $0}}' | awk '{{split($NF,a,\";\"); $NF=\"\"; for(x in a) if(a[x] ~ /Name=/) print $0,a[x]}}' | sed 's/Name=//' > {BASE}.admixmap.preannt.txt"
        shell(cmd)
        shell(f"{CMD_PREFIX} Rscript {CODE}/admixAnnt.R -i input/ -p {BASE}.admixmap.preannt.txt -b {config['admixMapping']['annotation_buffer']} -o {{output}}")


rule conditional_analysis:
    input: f"{BASE}.genesis.gds", f"{BASE}.genesis.pdat", f"{BASE}.genesis.grm.gds"
    output: f'conditional-analysis/{BASE}-{{marker}}.genesis.txt'
    run:
        if os.path.exists(config['conditional_analysis']['snp_list']):
            if not os.path.exists('conditional-analysis'): os.mkdir('conditional-analysis')
            chrom, pos = f"{wildcards.marker}".split("-")
            shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --snp {wildcards.marker.replace('-',':')} --recodeAD --out conditional-analysis/{wildcards.marker} {plnk_rsrc(rule, plink_run_specs)} || true")
            if os.path.exists(f"conditional-analysis/{wildcards.marker}.raw"):
                shell(f"{CMD_PREFIX} Rscript {CODE}/genesis_conditional_analysis.R -a {chrom} -b {pos} -d {config['conditional_analysis']['distance']} "
                      f"-m conditional-analysis/{wildcards.marker}.raw "
                      f"-g {{input[0]}} -p {{input[1]}} -k {{input[2]}} -n {config['gwas']['pc_num']} -C {config['gwas']['other_predictors']} "
                      f"-o conditional-analysis/{BASE}-{wildcards.marker}.genesis.txt")
            else:
                print(f"Did not find {wildcards.marker} in plink/{BASE}_sub_mflt")
                shell(f"touch conditional-analysis/{BASE}-{wildcards.marker}.genesis.txt")

rule combine_conditional_analysis:
    input: get_conditional_analysis_input
    output: f"conditional-analysis/{BASE}.conditional-analysis.genesis.txt"
    shell:
        f"for f in conditional-analysis/*genesis.txt; do " \
        "awk '{{print FILENAME, $0}}' $f | grep -v variant > conditional-analysis/tail.txt; " \
        f"head -q -n 1 conditional-analysis/*genesis.txt | uniq | " \
        "awk '{{printf(\"marker_covar\\t%s\\n\", $0}}' > conditional-analysis/head.txt; " \
        f"cat conditional-analysis/head.txt conditional-analysis/tail.txt > {{output}}"

rule polygenic_scores:
    input: f"{BASE}.genesis.txt"
    output: f"PRS/{BASE}.prs.txt"
    run:
        if not os.path.exists('PRS'): os.mkdir('PRS')
        if os.path.exists(config['polygenic_scores']['snp_list']):
            shell(f"{CMD_PREFIX} plink --bfile plink/{BASE}_sub_mflt --extract {config['polygenic_scores']['snp_list']} --keep-allele-order --allow-no-sex --recodeAD --out PRS/PRS_genotypes {plnk_rsrc(rule, plink_run_specs)} || true")
            shell(f"head -n 1 {BASE}.genesis.txt > PRS/head.txt; grep -f {config['polygenic_scores']['snp_list']} {BASE}.genesis.txt > PRS/body.txt")
            shell(f"cat PRS/head.txt PRS/body.txt > PRS/PRS_betas.txt; rm PRS/head.txt; rm PRS/body.txt")
            shell(f"{CMD_PREFIX} Rscript scripts/PRS.R -g PRS/PRS_genotypes.raw -b PRS/PRS_betas.txt -o PRS/{BASE}")
        else:
            print("Did not find snp_list")

